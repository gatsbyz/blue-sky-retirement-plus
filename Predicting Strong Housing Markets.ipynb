{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model to Predict Strong Housing Markets\n",
    "\n",
    "This model will assess past characteristics of strong markets to predict future performance in 400+ US metropolitan areas.  \n",
    "\n",
    "## About the model:\n",
    "\n",
    "\n",
    "1. Logistic Regression Supervised Learning Model used to identify the top 90th percentile markets based on home price index growth.  \n",
    "\n",
    "2. Employment data from the BLS was used to compute y/y growth for each of the 400+ markets. \n",
    "\n",
    "3. Home price index (HPI) data was drawn from the FHFA to compute y/y growth in home prices in each of the 400_ markets.  \n",
    "\n",
    "4. Data sets were indexed by the MSA names which were manually adjusted to easily merge the two data sets for analysis.  \n",
    "\n",
    "5. Lag variables were added as features for HPI and employment.  \n",
    "\n",
    "6. Employment and HPI data were grouped into periods of five years starting from 1991 to 2021.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the `transaction_fraud_data.csv` file from the `Resources` folder into a Pandas DataFrame. Set the “id” column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%hpi</th>\n",
       "      <th>rank</th>\n",
       "      <th>%hpi_lag</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Employment_ Lag</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene, TX</th>\n",
       "      <td>0.149704</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.009124</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1996-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akron, OH</th>\n",
       "      <td>0.129769</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.016294</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1996-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany, GA</th>\n",
       "      <td>0.126767</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007567</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1996-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Lebanon, OR</th>\n",
       "      <td>0.108796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1996-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Schenectady-Troy, NY</th>\n",
       "      <td>0.107624</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.014653</td>\n",
       "      <td>1.66</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1996-2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 %hpi  rank  %hpi_lag  Employment  \\\n",
       "MSA                                                                 \n",
       "Abilene, TX                  0.149704     1 -0.009124        0.68   \n",
       "Akron, OH                    0.129769     1 -0.016294        0.94   \n",
       "Albany, GA                   0.126767     1 -0.007567        0.04   \n",
       "Albany-Lebanon, OR           0.108796     1  0.002857        0.64   \n",
       "Albany-Schenectady-Troy, NY  0.107624     1 -0.014653        1.66   \n",
       "\n",
       "                             Employment_ Lag    Period   \n",
       "MSA                                                      \n",
       "Abilene, TX                             2.26  1996-2000  \n",
       "Akron, OH                               2.04  1996-2000  \n",
       "Albany, GA                              2.76  1996-2000  \n",
       "Albany-Lebanon, OR                      3.48  1996-2000  \n",
       "Albany-Schenectady-Troy, NY            -0.06  1996-2000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the project_2_data.csv file into a PandasDataFrame.\n",
    "housing_data = pd.read_csv(\n",
    "    Path('./Resources/project_2_data_2.csv'), \n",
    "    index_col='MSA'\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "housing_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Answer the following question:\n",
    "\n",
    "Note that you want to predict the `fraud` variable. Answer the following question: Using `value_counts`, how many fraudulent transactions exist in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1444\n",
       "1     151\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The  column 'fraud' is the thing you want to predict. \n",
    "# Class 0 indicates no-fraud trasactions and class 1 indicates fraudulent transactions\n",
    "# Using value_counts, how many fraudulent transactions are in this dataset?\n",
    "housing_data['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Using the `transaction_fraud_data` DataFrame, separate the data into training and testing data. Start by defining the `target` (the “fraud” column) and the `features` of the data (all the columns except “fraud”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target column should be the binary `fraud` column.\n",
    "y = housing_data['rank']\n",
    "\n",
    "\n",
    "# The features column should be all of the features. \n",
    "X = housing_data.drop(columns=['rank','Period ']).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split the features and target data into `training_features`, `testing_features`, `training_targets`, and `testing_targets` datasets by using the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset using the train_test_split function\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Fit the Data to a Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Declare a `LogisticRegression` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression model.\n",
    "# Apply a random_state of 7 to the model\n",
    "logistic_regression_model = LogisticRegression(random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit the training data to the model, and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and save the logistic regression model using the training data\n",
    "lr_model = logistic_regression_model.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the Testing Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Make predictions about fraud by using the testing dataset, and save those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "testing_predections = lr_model.predict(X_testing)\n",
    "\n",
    "# Review the predictions\n",
    "testing_predections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate the accuracy score by evaluating `testing_targets` vs. `testing_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899749373433584"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the accuracy score for the test dataset.\n",
    "accuracy_score(y_testing, testing_predections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the strongest housing market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%hpi</th>\n",
       "      <th>rank</th>\n",
       "      <th>%hpi_lag</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Employment_ Lag</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene, TX</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2016-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akron, OH</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2016-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany, GA</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2016-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Lebanon, OR</th>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2016-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Schenectady-Troy, NY</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2016-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             %hpi  rank  %hpi_lag  Employment  \\\n",
       "MSA                                                             \n",
       "Abilene, TX                  0.07     0      0.03        1.15   \n",
       "Akron, OH                    0.06     0      0.01       -0.87   \n",
       "Albany, GA                   0.06     0     -0.02        0.02   \n",
       "Albany-Lebanon, OR           0.12     1      0.02        1.33   \n",
       "Albany-Schenectady-Troy, NY  0.05     0      0.00       -0.32   \n",
       "\n",
       "                             Employment_ Lag    Period   \n",
       "MSA                                                      \n",
       "Abilene, TX                             0.78  2016-2021  \n",
       "Akron, OH                               1.18  2016-2021  \n",
       "Albany, GA                              0.10  2016-2021  \n",
       "Albany-Lebanon, OR                      1.92  2016-2021  \n",
       "Albany-Schenectady-Troy, NY             1.20  2016-2021  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the predicting_data.csv file into a PandasDataFrame.\n",
    "predicting_data = pd.read_csv(\n",
    "    Path(\"./Resources/predicting_data.csv\"), \n",
    "    index_col=\"MSA\"\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "predicting_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = predicting_data.drop(columns=['rank','Period ']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%hpi</th>\n",
       "      <th>%hpi_lag</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Employment_ Lag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene, TX</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akron, OH</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany, GA</th>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Lebanon, OR</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Schenectady-Troy, NY</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             %hpi  %hpi_lag  Employment  Employment_ Lag\n",
       "MSA                                                                     \n",
       "Abilene, TX                  0.07      0.03        1.15             0.78\n",
       "Akron, OH                    0.06      0.01       -0.87             1.18\n",
       "Albany, GA                   0.06     -0.02        0.02             0.10\n",
       "Albany-Lebanon, OR           0.12      0.02        1.33             1.92\n",
       "Albany-Schenectady-Troy, NY  0.05      0.00       -0.32             1.20"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save predictions with the saved logistic regression model\n",
    "\n",
    "predections = lr_model.predict(X_new)\n",
    "\n",
    "# Review the predictions\n",
    "predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred = pd.DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
